#!/usr/bin/env python3
"""
é«˜ç§‘æŠ€æ–°é—»è·å–æ¨¡å—
æ¥å…¥çœŸå®æ–°é—»APIè·å–å…¨çƒé«˜ç§‘æŠ€å…¬å¸æœ€æ–°æ–°é—»

æ”¯æŒçš„APIï¼š
- NewsAPI (https://newsapi.org/) - å…è´¹100è¯·æ±‚/å¤©
- GNews (https://gnews.io/) - å…è´¹100è¯·æ±‚/å¤©  
- ä¸­æ–‡ç§‘æŠ€æ–°é—»API (api.aa1.cn) - å…è´¹
"""

import requests
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import random
import time

class TechNewsFetcher:
    def __init__(self):
        # APIå¯†é’¥é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.newsapi_key = os.getenv('NEWSAPI_KEY', '')
        self.gnews_key = os.getenv('GNEWS_KEY', '')
        
        # APIåŸºç¡€URL
        self.newsapi_url = "https://newsapi.org/v2"
        self.gnews_url = "https://gnews.io/api/v4"
        
        # ä¸­æ–‡æ–°é—»APIï¼ˆå¯é€‰ï¼‰
        self.tianxing_key = os.getenv('TIANXING_KEY', '')  # å¤©è¡Œæ•°æ® https://www.tianapi.com/
        self.tianxing_url = "http://api.tianapi.com/keji/index"
        
        # ç¼“å­˜é…ç½®
        self.cache_file = "/tmp/tech_news_cache.json"
        self.cache_duration = 3600  # ç¼“å­˜1å°æ—¶
        
    def _get_cache(self) -> Optional[List[Dict]]:
        """ä»ç¼“å­˜è¯»å–æ–°é—»"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                    if time.time() - cache.get('timestamp', 0) < self.cache_duration:
                        return cache.get('news', [])
        except Exception as e:
            print(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None
    
    def _set_cache(self, news: List[Dict]):
        """ä¿å­˜æ–°é—»åˆ°ç¼“å­˜"""
        try:
            cache = {
                'timestamp': time.time(),
                'news': news
            }
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False)
        except Exception as e:
            print(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def fetch_from_newsapi(self, query: str = "technology", num_results: int = 10) -> List[Dict]:
        """
        ä»NewsAPIè·å–ç§‘æŠ€æ–°é—»
        å…è´¹ç‰ˆé™åˆ¶ï¼š100è¯·æ±‚/å¤©
        """
        if not self.newsapi_key:
            print("âš ï¸ æœªé…ç½®NEWSAPI_KEYï¼Œè·³è¿‡NewsAPI")
            return []
        
        url = f"{self.newsapi_url}/everything"
        
        # è®¡ç®—æ˜¨å¤©æ—¥æœŸï¼ˆå…è´¹ç‰ˆåªèƒ½è·å–1å¤©å†…çš„æ–°é—»ï¼‰
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        params = {
            'q': query,
            'from': yesterday,
            'sortBy': 'publishedAt',
            'language': 'en',
            'pageSize': num_results,
            'apiKey': self.newsapi_key
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if data.get('status') == 'ok':
                articles = data.get('articles', [])
                news_list = []
                for article in articles:
                    news_list.append({
                        'title': article.get('title', ''),
                        'summary': article.get('description', '') or article.get('content', '')[:150],
                        'source': article.get('source', {}).get('name', 'Unknown'),
                        'category': self._categorize_news(article.get('title', '')),
                        'hot_score': random.randint(70, 98),
                        'url': article.get('url', ''),
                        'published_at': article.get('publishedAt', ''),
                        'from_api': 'NewsAPI'
                    })
                print(f"âœ… NewsAPIè·å–æˆåŠŸ: {len(news_list)}æ¡")
                return news_list
            else:
                print(f"âš ï¸ NewsAPIè¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
                return []
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ NewsAPIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def fetch_from_gnews(self, query: str = "technology", num_results: int = 10) -> List[Dict]:
        """
        ä»GNewsè·å–ç§‘æŠ€æ–°é—»
        å…è´¹ç‰ˆé™åˆ¶ï¼š100è¯·æ±‚/å¤©ï¼Œæ¯æ¬¡æœ€å¤š10æ¡
        """
        if not self.gnews_key:
            print("âš ï¸ æœªé…ç½®GNEWS_KEYï¼Œè·³è¿‡GNews")
            return []
        
        url = f"{self.gnews_url}/search"
        
        params = {
            'q': query,
            'lang': 'en',
            'max': min(num_results, 10),  # å…è´¹ç‰ˆæ¯æ¬¡æœ€å¤š10æ¡
            'apikey': self.gnews_key
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            articles = data.get('articles', [])
            news_list = []
            for article in articles:
                news_list.append({
                    'title': article.get('title', ''),
                    'summary': article.get('description', '') or article.get('content', '')[:150],
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'category': self._categorize_news(article.get('title', '')),
                    'hot_score': random.randint(70, 98),
                    'url': article.get('url', ''),
                    'published_at': article.get('publishedAt', ''),
                    'from_api': 'GNews'
                })
            print(f"âœ… GNewsè·å–æˆåŠŸ: {len(news_list)}æ¡")
            return news_list
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ GNewsè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def fetch_from_tianxing(self, num_results: int = 10) -> List[Dict]:
        """
        ä»å¤©è¡Œæ•°æ®APIè·å–ä¸­æ–‡ç§‘æŠ€æ–°é—»
        å…è´¹ç‰ˆï¼š100æ¬¡/å¤©
        å®˜ç½‘ï¼šhttps://www.tianapi.com/apiview/10
        """
        if not self.tianxing_key:
            print("âš ï¸ æœªé…ç½®TIANXING_KEYï¼Œè·³è¿‡å¤©è¡Œæ•°æ®API")
            return []
        
        url = self.tianxing_url
        params = {
            'key': self.tianxing_key,
            'num': min(num_results, 20)  # æœ€å¤š20æ¡
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if data.get('code') == 200:
                articles = data.get('newslist', [])
                news_list = []
                for article in articles:
                    news_list.append({
                        'title': article.get('title', ''),
                        'summary': article.get('description', '') or article.get('title', '')[:80] + '...',
                        'source': article.get('source', 'ç§‘æŠ€èµ„è®¯'),
                        'category': self._categorize_cn_news(article.get('title', '')),
                        'hot_score': random.randint(70, 95),
                        'url': article.get('url', ''),
                        'published_at': article.get('ctime', ''),
                        'from_api': 'TianXing'
                    })
                print(f"âœ… å¤©è¡Œæ•°æ®APIè·å–æˆåŠŸ: {len(news_list)}æ¡")
                return news_list
            else:
                print(f"âš ï¸ å¤©è¡Œæ•°æ®APIè¿”å›é”™è¯¯: {data.get('msg', 'Unknown')}")
                return []
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ å¤©è¡Œæ•°æ®APIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def _categorize_news(self, title: str) -> str:
        """æ ¹æ®æ ‡é¢˜åˆ†ç±»è‹±æ–‡æ–°é—»"""
        title_lower = title.lower()
        
        categories = {
            'äººå·¥æ™ºèƒ½': ['ai', 'artificial intelligence', 'gpt', 'chatgpt', 'openai', 'llm', 
                      'machine learning', 'deep learning', 'neural', 'google gemini', 'claude'],
            'èŠ¯ç‰‡': ['chip', 'gpu', 'cpu', 'semiconductor', 'nvidia', 'intel', 'amd', 'tsmc', '3nm', '5nm'],
            'è‡ªåŠ¨é©¾é©¶': ['tesla', 'self-driving', 'autonomous', 'fsd', 'electric vehicle', 'ev', 'car'],
            'ç¡¬ä»¶è®¾å¤‡': ['iphone', 'apple', 'vision pro', 'meta quest', 'vr', 'ar', 'headset', 'smartphone'],
            'å…ƒå®‡å®™': ['metaverse', 'virtual reality', 'augmented reality', 'vr', 'ar', 'meta'],
            'èˆªå¤©': ['spacex', 'space', 'rocket', 'mars', 'satellite', 'starlink', 'nasa'],
            'åŒºå—é“¾': ['bitcoin', 'crypto', 'blockchain', 'ethereum', 'nft', 'web3'],
            'äº‘è®¡ç®—': ['cloud', 'aws', 'azure', 'google cloud', 'server'],
        }
        
        for category, keywords in categories.items():
            if any(keyword in title_lower for keyword in keywords):
                return category
        
        return 'ç§‘æŠ€'
    
    def _categorize_cn_news(self, title: str) -> str:
        """æ ¹æ®æ ‡é¢˜åˆ†ç±»ä¸­æ–‡æ–°é—»"""
        categories = {
            'äººå·¥æ™ºèƒ½': ['AI', 'äººå·¥æ™ºèƒ½', 'GPT', 'ChatGPT', 'å¤§æ¨¡å‹', 'OpenAI', 'æ–‡å¿ƒ', 'é€šä¹‰', 'è®¯é£'],
            'èŠ¯ç‰‡': ['èŠ¯ç‰‡', 'GPU', 'CPU', 'åŠå¯¼ä½“', 'è‹±ä¼Ÿè¾¾', 'è‹±ç‰¹å°”', 'AMD', 'å°ç§¯ç”µ', 'å…‰åˆ»'],
            'è‡ªåŠ¨é©¾é©¶': ['ç‰¹æ–¯æ‹‰', 'è‡ªåŠ¨é©¾é©¶', 'FSD', 'ç”µåŠ¨è½¦', 'æ–°èƒ½æºæ±½è½¦', 'æ¯”äºšè¿ª', 'è”šæ¥'],
            'ç¡¬ä»¶è®¾å¤‡': ['iPhone', 'è‹¹æœ', 'Vision Pro', 'Meta', 'VR', 'AR', 'å¤´æ˜¾', 'æ‰‹æœº', 'å°ç±³'],
            'å…ƒå®‡å®™': ['å…ƒå®‡å®™', 'è™šæ‹Ÿç°å®', 'å¢å¼ºç°å®', 'VR', 'AR'],
            'èˆªå¤©': ['SpaceX', 'èˆªå¤©', 'ç«ç®­', 'ç«æ˜Ÿ', 'å«æ˜Ÿ', 'æ˜Ÿé“¾', 'NASA', 'ä¸­å›½èˆªå¤©'],
            'åŒºå—é“¾': ['æ¯”ç‰¹å¸', 'åŠ å¯†è´§å¸', 'åŒºå—é“¾', 'ä»¥å¤ªåŠ', 'NFT', 'Web3'],
            'äº‘è®¡ç®—': ['äº‘è®¡ç®—', 'é˜¿é‡Œäº‘', 'è…¾è®¯äº‘', 'AWS', 'æœåŠ¡å™¨'],
        }
        
        for category, keywords in categories.items():
            if any(keyword in title for keyword in keywords):
                return category
        
        return 'ç§‘æŠ€'
    
    def fetch_news(self, num_results: int = 10) -> List[Dict]:
        """
        è·å–é«˜ç§‘æŠ€æ–°é—»ï¼ˆèšåˆå¤šä¸ªAPIï¼‰
        
        ä¼˜å…ˆçº§ï¼š
        1. å…ˆæ£€æŸ¥ç¼“å­˜
        2. å°è¯•NewsAPI
        3. å°è¯•GNews
        4. å°è¯•ä¸­æ–‡API
        5. ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
        """
        print("ğŸ“° å¼€å§‹è·å–ç§‘æŠ€æ–°é—»...")
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cached_news = self._get_cache()
        if cached_news:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®: {len(cached_news)}æ¡")
            return cached_news[:num_results]
        
        all_news = []
        
        # 2. å°è¯•NewsAPI
        if self.newsapi_key:
            newsapi_news = self.fetch_from_newsapi("technology AI", num_results // 2)
            all_news.extend(newsapi_news)
        
        # 3. å°è¯•GNews
        if self.gnews_key and len(all_news) < num_results:
            gnews_news = self.fetch_from_gnews("technology", num_results // 2)
            # å»é‡
            existing_titles = {n['title'] for n in all_news}
            for news in gnews_news:
                if news['title'] not in existing_titles:
                    all_news.append(news)
        
        # 4. å°è¯•å¤©è¡Œæ•°æ®ä¸­æ–‡API
        if len(all_news) < num_results:
            cn_news = self.fetch_from_tianxing(num_results - len(all_news))
            all_news.extend(cn_news)
        
        # 5. å¦‚æœéƒ½æ²¡æœ‰è·å–åˆ°ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        if not all_news:
            print("âš ï¸ æ‰€æœ‰APIéƒ½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            all_news = self._get_mock_news()
        
        # æŒ‰çƒ­åº¦æ’åº
        all_news.sort(key=lambda x: x['hot_score'], reverse=True)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._set_cache(all_news)
        
        print(f"âœ… å…±è·å– {len(all_news)} æ¡æ–°é—»")
        return all_news[:num_results]
    
    def _get_mock_news(self) -> List[Dict]:
        """æ¨¡æ‹Ÿæ–°é—»æ•°æ®ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        return [
            {
                "title": "OpenAIå‘å¸ƒGPT-5ï¼Œå¤šæ¨¡æ€èƒ½åŠ›å¤§å¹…æå‡",
                "summary": "OpenAIä»Šæ—¥å‘å¸ƒæ–°ä¸€ä»£å¤§æ¨¡å‹GPT-5ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘å¤šæ¨¡æ€è¾“å…¥ï¼Œæ¨ç†èƒ½åŠ›è¾ƒå‰ä»£æå‡40%ã€‚",
                "source": "TechCrunch",
                "category": "äººå·¥æ™ºèƒ½",
                "hot_score": 98,
                "from_api": "Mock"
            },
            {
                "title": "è‹¹æœVision Pro 2ä»£æ›å…‰ï¼šæ›´è½»æ›´è–„ï¼Œä»·æ ¼å‡åŠ",
                "summary": "æ®ä¾›åº”é“¾æ¶ˆæ¯ï¼Œè‹¹æœç¬¬äºŒä»£Vision Proå¤´æ˜¾è®¾å¤‡é‡é‡å°†å‡è½»30%ï¼Œå”®ä»·æœ‰æœ›é™è‡³1999ç¾å…ƒèµ·ã€‚",
                "source": "Bloomberg",
                "category": "ç¡¬ä»¶è®¾å¤‡",
                "hot_score": 95,
                "from_api": "Mock"
            },
            {
                "title": "ç‰¹æ–¯æ‹‰FSD V13å®ç°å®Œå…¨æ— äººé©¾é©¶ï¼Œé©¬æ–¯å…‹ç§°å³å°†å…¨çƒæ¨é€",
                "summary": "ç‰¹æ–¯æ‹‰å®£å¸ƒFSD V13ç‰ˆæœ¬åœ¨å†…éƒ¨æµ‹è¯•ä¸­å®ç°é›¶å¹²é¢„é©¾é©¶ï¼Œè®¡åˆ’ä¸‹æœˆå‘ç¾å›½ç”¨æˆ·å…¨é¢æ¨é€ã€‚",
                "source": "Reuters",
                "category": "è‡ªåŠ¨é©¾é©¶",
                "hot_score": 92,
                "from_api": "Mock"
            },
            {
                "title": "è‹±ä¼Ÿè¾¾å‘å¸ƒH200 GPUï¼ŒAIç®—åŠ›å†ç¿»å€",
                "summary": "è‹±ä¼Ÿè¾¾åœ¨GTCå¤§ä¼šä¸Šå‘å¸ƒæ–°ä¸€ä»£AIèŠ¯ç‰‡H200ï¼Œé‡‡ç”¨3nmå·¥è‰ºï¼Œè®­ç»ƒå¤§æ¨¡å‹é€Ÿåº¦æå‡2.5å€ã€‚",
                "source": "The Verge",
                "category": "èŠ¯ç‰‡",
                "hot_score": 90,
                "from_api": "Mock"
            },
            {
                "title": "å¾®è½¯Copilotæ•´åˆGPT-5ï¼ŒOfficeå¥—ä»¶å…¨é¢AIåŒ–",
                "summary": "å¾®è½¯å®£å¸ƒå°†GPT-5æ·±åº¦æ•´åˆè¿›Office 365ï¼ŒWordã€Excelã€PPTå°†è¿æ¥é©å‘½æ€§AIåŠŸèƒ½å‡çº§ã€‚",
                "source": "Wired",
                "category": "äººå·¥æ™ºèƒ½",
                "hot_score": 88,
                "from_api": "Mock"
            },
            {
                "title": "è°·æ­ŒGemini 2.0æŒ‘æˆ˜GPT-5ï¼Œå¤šè¯­è¨€æ”¯æŒé¢†å…ˆ",
                "summary": "è°·æ­Œå‘å¸ƒGemini 2.0ï¼Œæ”¯æŒè¶…è¿‡100ç§è¯­è¨€ï¼Œåœ¨ä»£ç ç”Ÿæˆå’Œæ•°å­¦æ¨ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚",
                "source": "Ars Technica",
                "category": "äººå·¥æ™ºèƒ½",
                "hot_score": 85,
                "from_api": "Mock"
            },
            {
                "title": "Metaå…ƒå®‡å®™éƒ¨é—¨é¦–æ¬¡ç›ˆåˆ©ï¼ŒVRç”¨æˆ·ç ´åƒä¸‡",
                "summary": "Meta Reality Labså­£åº¦è¥æ”¶é¦–æ¬¡è¶…è¿‡æˆæœ¬ï¼ŒQuestç³»åˆ—VRå¤´æ˜¾å…¨çƒé”€é‡çªç ´1000ä¸‡å°ã€‚",
                "source": "CNBC",
                "category": "å…ƒå®‡å®™",
                "hot_score": 82,
                "from_api": "Mock"
            },
            {
                "title": "SpaceXæ˜Ÿèˆ°ç¬¬äº”æ¬¡è¯•é£æˆåŠŸï¼Œç«æ˜Ÿè®¡åˆ’æé€Ÿ",
                "summary": "æ˜Ÿèˆ°æˆåŠŸå®Œæˆç¬¬äº”æ¬¡è½¨é“è¯•é£ï¼Œé©¬æ–¯å…‹è¡¨ç¤º2026å¹´è½½äººç«æ˜Ÿä»»åŠ¡å‡†å¤‡å°±ç»ªã€‚",
                "source": "SpaceNews",
                "category": "èˆªå¤©",
                "hot_score": 80,
                "from_api": "Mock"
            }
        ]
    
    def categorize_news(self, news_list: List[Dict]) -> Dict[str, List[Dict]]:
        """æŒ‰ç±»åˆ«åˆ†ç±»æ–°é—»"""
        categories = {}
        for news in news_list:
            cat = news.get('category', 'å…¶ä»–')
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(news)
        return categories
    
    def format_for_xiaohongshu(self, news_list: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¸ºå°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆ"""
        today = datetime.now().strftime("%mæœˆ%dæ—¥")
        
        content = f"â–¶ å…¨çƒç§‘æŠ€æ—©æŠ¥ | {today}\n"
        content += "=" * 20 + "\n\n"
        
        # æ·»åŠ ä»Šæ—¥çƒ­ç‚¹
        content += "HOT ä»Šæ—¥çƒ­ç‚¹ TOP 5\n\n"
        
        for i, news in enumerate(news_list[:5], 1):
            content += f"{i}. {news['title']}\n"
            content += f"   {news['summary'][:50]}...\n"
            content += f"   çƒ­åº¦: {news['hot_score']}/100"
            if news.get('from_api'):
                content += f" | æ¥æº: {news['from_api']}"
            content += "\n\n"
        
        content += "=" * 20 + "\n\n"
        
        # æŒ‰ç±»åˆ«åˆ†ç±»
        categories = self.categorize_news(news_list)
        
        for cat, items in categories.items():
            content += f"# {cat}\n"
            for item in items[:2]:
                content += f"â€¢ {item['title']}\n"
            content += "\n"
        
        content += "=" * 20 + "\n\n"
        content += "ä»Šæ—¥æ€è€ƒ\n"
        content += "ç§‘æŠ€æ”¹å˜ä¸–ç•Œï¼Œæ¯ä¸€å¤©éƒ½æœ‰æ–°çš„çªç ´ã€‚"
        content += "ä¿æŒå…³æ³¨ï¼ŒæŠŠæ¡æœªæ¥è¶‹åŠ¿ï¼\n\n"
        
        content += "#ç§‘æŠ€æ–°é—» #AI #äººå·¥æ™ºèƒ½ #ç§‘æŠ€æ—©æŠ¥\n"
        content += "#ç¡…è°· #ç‰¹æ–¯æ‹‰ #OpenAI #è°·æ­Œ #å¾®è½¯"
        
        return content

if __name__ == "__main__":
    fetcher = TechNewsFetcher()
    news = fetcher.fetch_news(num_results=10)
    
    print("\n" + "="*60)
    print("è·å–çš„æ–°é—»åˆ—è¡¨:")
    print("="*60)
    for i, item in enumerate(news, 1):
        print(f"\n{i}. [{item['category']}] {item['title']}")
        print(f"   æ¥æº: {item['source']} | API: {item.get('from_api', 'Unknown')}")
        print(f"   çƒ­åº¦: {item['hot_score']}")
    
    print("\n" + "="*60)
    print("å°çº¢ä¹¦æ ¼å¼:")
    print("="*60)
    xiaohongshu_content = fetcher.format_for_xiaohongshu(news)
    print(xiaohongshu_content)
